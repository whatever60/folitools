# folitools

**folitools** is a modular CLI toolkit and python library for Foli-seq data processing.

Foli-seq is a amplicon-based high-throughput sequencing method for profiling host gene expression from feces. Foli-seq is developed to probe amplicons of 320-380bp and sequence on PE150 Illumina sequencers.

---

## Installation

Install from PyPI:

```bash
pip install folitools
```

The dependencies from conda are also required:

```bash
conda install -c bioconda -c conda-forge \
  fastp cutadapt samtools bwa-mem2 star seqkit fastqc subread sambamba pigz
```

## Usage

Each stage of the pipeline is exposed as a command via `foli <subcommand>`.

**A note on input paths**: All commands that accept input paths through the `--input` parameter allow files locations of absolute paths, relative paths, or glob patterns. Multiple paths/patterns are also allowed.

**A note on paired-end files**: Foli-seq uses paired-end sequencing. When inputing FASTQ files, only R1 path is given to the command and the corresponding R2 files are automatically derived by replacing the R1 pattern with R2 pattern (e.g., `_R1_` → `_R2_`, `_1` → `_2`). Both R1 and R2 files are required for the pipeline to work.

### Expected Inputs

- Raw paired-end FASTQ files (following the naming pattern `*_R1_*.fastq.gz` and `*_R2_*.fastq.gz`)
- Adapter FASTA files
- STAR genome index directory
- GTF annotation file

Output directories are automatically created if they don't exist.

### Step 1. Preprocessing

```bash
foli qc \
    --input "/path/to/fastq/*_R1_*.fastq.gz" \
    --output-dir "/path/to/trimmed_reads"
```

This command performs read trimming using `fastp` and runs quality check on output files with `fastqc` and `seqkit`.

**What happens under the hood:**
1. `fastp` performs quality-based trimming with tail trimming and error correction
2. `fastqc` generates quality control reports for the trimmed reads
3. `seqkit stats` compiles summary statistics for all output files

You can specify input FASTQ files from any location using absolute paths, relative paths, or glob patterns. The paired-end R2 files are automatically derived from R1 files by replacing `_R1_` with `_R2_` (or `_1` with `_2`).

Output files (in the specified output directory):
- `{sample_name}_1.fq.gz` and `{sample_name}_2.fq.gz`: Trimmed paired-end reads
- `{sample_name}.fastp.html` and `{sample_name}.fastp.json`: fastp QC reports
- FastQC reports in `{output_dir}_fastqc/`
- `{output_dir}.stats`: Summary statistics table generated by seqkit

### Step 2. Probe assignment

```bash
foli assign-probes \
    --input "/path/to/trimmed_reads/*_1.fq.gz" \
    --output-dir "/path/to/umi_tagged" \
    --i5 "/path/to/i5_short.fasta" \
    --i7 "/path/to/i7_short.fasta"
```

This command performs gene probe primer assignment and trimming using `cutadapt`. This step extracts UMI sequences from adapter matches and embeds them in read names for downstream processing.

**What happens under the hood:**
1. `cutadapt` identifies i5 and i7 adapters in the reads (minimum 20bp overlap, 10% error rate)
2. Adapter sequences and primer names are added to read headers
3. A custom Python script (`folitools.add_umi`) parses the adapter information and embeds UMI sequences into read names in a structured format
4. `seqkit stats` generates summary statistics for the output files

After probe assignment, you can get read statistics:

```bash
foli get-read-stats \
    --input "/path/to/umi_tagged/*_1.fq.gz" \
    --output-dir "/path/to/read_stats" \
    --overwrite
```

This analyzes the UMI-tagged reads to generate detailed statistics about primer assignment and read characteristics.

Output files:
- `{sample_name}_1.fq.gz` and `{sample_name}_2.fq.gz`: UMI-tagged, adapter-trimmed reads with UMI information embedded in read names
- `{output_dir}.stats`: Summary statistics table generated by seqkit
- Read statistics: `{sample_name}.parquet` files in the stats output directory (when using `foli get-read-stats`)

### Step 3. Mapping and Feature Counting

```bash
foli map \
    --input "/path/to/umi_tagged/*_1.fq.gz" \
    --output-bam "/path/to/mapped_reads" \
    --output-star "/path/to/star" \
    --star-index "/path/to/star_index" \
    --gtf "/path/to/annotation.gtf"
```

This command performs streamlined alignment and feature counting using `STAR` and `featureCounts`.

**What happens under the hood:**
1. **STAR index preloading**: The genome index is loaded into shared memory once for all samples to improve processing speed
2. **Read filtering**: Short reads (< 60bp, considered primer dimers) are removed using `cutadapt`
3. **Alignment**: Filtered reads are aligned to the genome using `STAR` with:
   - Support for up to 1000 multi-mapping locations
   - Unmapped reads included in output (`--outSAMunmapped Within`)
   - Chimeric alignments detected and marked (`--chimOutType WithinBAM`)
4. **Feature assignment**: `featureCounts` assigns aligned reads to genomic features from the GTF file
5. **BAM tagging and sorting**: 
   - UMI sequences are added as BAM tags (`US` for raw UMI, `UC` for filtered UMI)
   - Cell barcodes added as `CB` tag
   - Gene assignments added as `XF` tag
   - BAM files are coordinate-sorted using `sambamba`

**Core allocation**: The `--cores` parameter is automatically split between STAR (70%) and featureCounts (30%) to optimize pipeline throughput.

For fractional counting of reads that overlap multiple features, you can use the `--allow-overlap` and `--allow-multimapping` flags:
```bash
foli map \
    --input "/path/to/umi_tagged/*_1.fq.gz" \
    --output-bam "/path/to/mapped_reads" \
    --output-star "/path/to/star" \
    --star-index "/path/to/star_index" \
    --gtf "/path/to/annotation.gtf" \
    --allow-overlap \
    --allow-multimapping
```

These flags enable fractional counting where reads overlapping multiple features or mapping to multiple locations contribute fractionally to each feature.

Output files:
- STAR alignment files in `{output_star}/{sample_name}/`:
  - `Aligned.out.bam`: Unsorted alignment file
  - `Log.final.out`, `Log.out`, `Log.progress.out`: STAR log files
  - `ReadsPerGene.out.tab`: Gene counts from STAR
- Sorted, tagged BAM files in `{output_bam}/`:
  - `{sample_name}.sorted.bam`: Final sorted BAM with UMI and gene tags
  - `{sample_name}.sorted.bam.bai`: BAM index file
- `featureCounts` results in `{output_bam}/`:
  - `{sample_name}.featureCounts`: Read-feature assignments
  - `{sample_name}.featureCounts.summary`: Assignment statistics

### Step 4. UMI-based Gene Counting

```bash
foli count \
    --input "/path/to/mapped_reads/*.sorted.bam" \
    --output-dir "/path/to/count_results"
```

This command processes BAM files using `umi_tools group` to generate UMI-deduplicated count data.

**What happens under the hood:**
1. **UMI grouping**: `umi_tools group` identifies and groups reads with:
   - The same UMI sequence (extracted from `UC` tag)
   - The same cell barcode (`CB` tag)
   - The same gene assignment (`XF` tag)
2. **Read handling**:
   - Paired-end reads are processed together
   - Unmapped reads, chimeric pairs, and unpaired reads are all retained in the output
   - Only primary alignments are used for grouping (secondary/supplementary alignments are ignored)
3. **Deduplication method**: Uses the "unique" method where only reads with identical UMI sequences are grouped together
4. **Output generation**: Produces detailed grouping information showing which reads were collapsed into each UMI group

Input BAM files should contain UMI tags (`UC`), cell tags (`CB`), and gene assignment tags (`XF`) from the previous mapping step.

After counting, generate the final count matrix:

```bash
foli get-count-mtx \
    --input "/path/to/count_results/*.group.tsv.gz" \
    --output "/path/to/final_counts.tsv" \
    --gtf "/path/to/annotation.gtf"
```

**What happens under the hood:**
1. Reads all UMI grouping tables from `umi_tools group` output
2. Counts unique UMI groups per gene per sample
3. If GTF is provided, maps gene IDs to gene symbols
4. Generates a gene × sample count matrix

You can also use the Python function directly:

```python
from folitools.get_matrix import read_counts
df = read_counts("/path/to/input_files", "/path/to/annotation.gtf")
df.to_csv("/path/to/output.tsv", sep="\t", index_label="gene")
```

Output files:
- `{sample_name}.group.tsv.gz`: UMI grouping tables with detailed information about which reads were grouped together
- `{sample_name}.group.log`: Processing logs showing statistics for each sample
- Final count matrix: Gene × sample matrix in TSV format with gene symbols (if GTF provided) or gene IDs

## Primer Selection Functionality

The primer selection module provides tools for designing and recovering PCR primer sets for targeted amplicon sequencing experiments.

### Workflow

The primer selection workflow provides a complete pipeline for primer design:

```bash
# Run complete primer design workflow using built-in reference
foli-primer workflow \
    --genes "genes.tsv" \
    --species "mouse" \
    --output-dir "primer_design/"

# Or use custom transcriptome FASTA for better coverage
foli-primer workflow \
    --genes "genes.tsv" \
    --txome-fasta "/path/to/transcriptome.fasta" \
    --output-dir "primer_design/"
```

**Input**: Gene table TSV with columns `gene` and `group`  
**Output**: Complete primer design including optimized primer sets, amplicon sequences, and IDT-compatible ordering files

**Note**: You can use either `--species` (mouse/human) for built-in references or `--txome-fasta` for custom transcriptome files. Custom FASTA files often provide better gene coverage than the built-in  references.

### Recover

The recover functionality helps validate and analyze primer sets from IDT order files:

```bash
# Recover primer information using built-in reference
foli-primer recover \
    --order-excel "idt_order.xlsx" \
    --output-dir "recovered_output/" \
    --species "human"

# Or use custom transcriptome FASTA (recommended for better coverage)
foli-primer recover \
    --order-excel "idt_order.xlsx" \
    --output-dir "recovered_output/" \
    --txome-fasta "/path/to/transcriptome.fasta"
```

This command analyzes primer sequences from an IDT order file, validates them against a reference transcriptome, and generates output files for downstream analysis. The output FASTA files (`i5_short.fasta` and `i7_short.fasta`) will contain the same number of unique primer sequences as found in the input Excel file, ensuring all original primers are represented.

**Note**: Using `--txome-fasta` with a custom transcriptome file is recommended over the built-in `--species` references as it typically provides better gene coverage than the packaged Gencode references.

You can also specify the amplicon length range, and whether the primers have linkers:
```bash
foli-primer recover \
    --order-excel "idt_order.xlsx" \
    --output-dir "recovered_output/" \
    --txome-fasta "/path/to/transcriptome.fasta" \
    --has-linker \
    --amplicon-length-range 300 400
```

**Input**: IDT order Excel file with primer sequences  
**Output**: 
- `summary_primer_to_order.xlsx`: Validated primer summary with amplicon information
- `primer_diagnose.pdf`: PDF report with analysis plots and statistics
- `i5_short.fasta` and `i7_short.fasta`: FASTA files for sequencing adapters

### Dimer Evaluation (through Python)

A primer set can be evaluated by calculating the thermodynamic properties of potential primer dimers for each pair of primers.

```python
from folitools.primer_selection.eval_dimer import dimer_thermo_property

# Evaluate primer-dimer interactions
result_matrix = dimer_thermo_property(
    primer_fwd_fasta="forward_primers.fasta",
    primer_rev_fasta="reverse_primers.fasta", 
    output_dir="dimer_analysis/",
    output_suffix="_analysis"
)
```

**Input**: FASTA files containing forward and reverse primer sequences  
**Output**: 
- Pairwise interaction matrix with thermodynamic properties
- Detailed analysis files in the output directory

## Testing

Run all tests:
```bash
pytest
```

Run only shell script tests:
```bash
pytest tests/test_shell_scripts.py -v
```

Run tests with coverage:
```bash
pytest --cov=src/folitools --cov-report=html
```

## TODO

- Add QC report code that summarizes all metrics into a table (need refactoring)
